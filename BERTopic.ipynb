{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e17780cb-55af-4711-a753-aea26f2a6a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/woosu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/woosu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/woosu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/woosu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bertopic import BERTopic\n",
    "import spacy\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import altair as alt\n",
    "from ugtm import eGTM\n",
    "import umap\n",
    "import hdbscan\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "import nltk\n",
    "from itertools import product\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from sklearn.preprocessing import normalize\n",
    "from gensim import corpora\n",
    "from gensim.models.coherencemodel import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd27d58-4222-4475-82cc-089e8fb3fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK 설정 및 리소스 다운로드\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d343141-acc4-475c-8e7f-01795ac62d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 불러오기\n",
    "csv_file_path = \"/Users/woosu/Desktop/project/port_patent_data.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "df['sum'] = df['sum'].fillna('')  # 누락된 값을 빈 문자열로 대체\n",
    "text_data = df['sum'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6eaeaa55-9a4d-4ef9-83dc-ffe4ee25edd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어 목록 설정\n",
    "stop_words = set(stopwords.words('english'))  # 영어 불용어 로드\n",
    "stop_words.update([\"first\", \"may\", \"one\", \"second\"])\n",
    "stop_words = list(stop_words)  # set을 list로 변환\n",
    "\n",
    "# 표제어 추출기 설정\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "788b864c-4fa0-4548-8f88-4c0da78b4043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordnet_pos_tags(treebank_tag):\n",
    "    \"\"\"Converts POS tags from treebank format to WordNet format.\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return 'a'  # adjective\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return 'v'  # verb\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return 'n'  # noun\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return 'r'  # adverb\n",
    "    else:\n",
    "        return 'n'  # default to noun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "03e29b81-0d4e-47c6-aef2-8300ab0d6070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_bertopic(documents):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    preprocessed_docs = []\n",
    "    for document in documents:\n",
    "        # 소문자 변환 및 특수 문자 제거\n",
    "        document = document.lower()\n",
    "        document = re.sub(r'\\s+', ' ', document)\n",
    "        document = document.strip()\n",
    "        \n",
    "        # 토크나이징 및 불용어 제거\n",
    "        tokens = word_tokenize(document)\n",
    "        tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "        \n",
    "        # 품사 태깅 및 표제어 추출\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(token, wordnet_pos_tags(tag)) for token, tag in pos_tags]\n",
    "        \n",
    "        # 전처리된 문서를 리스트에 추가\n",
    "        preprocessed_docs.append(\" \".join(lemmatized_tokens))\n",
    "    return preprocessed_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4ddd763-a4f1-4700-a2b9-0119eda89d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "preprocessed_docs = preprocess_for_bertopic(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "997e9b9d-fc6c-4774-85a4-b29fea371b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 임베딩 모델\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# 커스텀 UMAP 모델\n",
    "umap_model = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=2,\n",
    "    min_dist=0.01,\n",
    "    spread=1.0\n",
    ")\n",
    "# 커스텀 HDBSCAN 모델\n",
    "hdbscan_model = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=5,\n",
    "    metric='euclidean',\n",
    "    prediction_data=True,\n",
    "    min_samples=5,\n",
    "    alpha=1.0\n",
    ")\n",
    "# CountVectorizer 설정\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=stop_words,\n",
    "    ngram_range=(1, 1)\n",
    ")\n",
    "\n",
    "# BERTopic 모델 초기화 및 훈련\n",
    "topic_model = BERTopic(\n",
    "    language=\"english\",  # 언어 설정\n",
    "    calculate_probabilities=True,  # 확률 계산 여부\n",
    "    nr_topics=10,  # 주제의 수 제한\n",
    "    top_n_words=10,  # 각 주제의 상위 단어 수\n",
    "    min_topic_size=5,  # 주제의 최소 크기\n",
    "    vectorizer_model=vectorizer_model,  # 벡터화 모델\n",
    "    embedding_model=embedding_model,  # 임베딩 모델\n",
    "    umap_model=umap_model,  # UMAP 모델\n",
    "    hdbscan_model=hdbscan_model,  # HDBSCAN 모델\n",
    "    ctfidf_model=None,  # c-TFIDF 모델\n",
    "    verbose=True  # 진행 상황 출력 여부\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3b627b54-808e-4e4e-8185-8521b2b8646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 11:10:32,873 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "033e6d60c05842949adcd79faf667b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-30 11:10:35,410 - BERTopic - Embedding - Completed ✓\n",
      "2024-05-30 11:10:35,410 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-05-30 11:10:37,376 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-05-30 11:10:37,377 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-05-30 11:10:37,546 - BERTopic - Cluster - Completed ✓\n",
      "2024-05-30 11:10:37,546 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-05-30 11:10:37,641 - BERTopic - Representation - Completed ✓\n",
      "2024-05-30 11:10:37,641 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2024-05-30 11:10:37,718 - BERTopic - Topic reduction - Reduced number of topics from 71 to 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# BERTopic 모델 훈련\n",
    "topics, probabilities = topic_model.fit_transform(preprocessed_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0c3503f6-bc1a-4305-a35d-dce2df8559d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                                     Name  \\\n",
      "0     -1    577          -1_system_data_container_device   \n",
      "1      0    350             0_network_device_data_system   \n",
      "2      1    248             1_item_vehicle_method_system   \n",
      "3      2    195         2_container_cargo_include_system   \n",
      "4      3     90                3_vessel_marine_ship_sail   \n",
      "5      4     25           4_image_container_include_form   \n",
      "6      5     16  5_radiation_source_detector_quasistatic   \n",
      "7      6     15        6_carrier_aspect_compute_waveform   \n",
      "8      7      6                 7_shaft_actuate_lock_fit   \n",
      "9      8      5             8_light_optical_object_lidar   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [system, data, container, device, include, met...   \n",
      "1  [network, device, data, system, signal, includ...   \n",
      "2  [item, vehicle, method, system, include, deliv...   \n",
      "3  [container, cargo, include, system, lock, sens...   \n",
      "4  [vessel, marine, ship, sail, system, position,...   \n",
      "5  [image, container, include, form, layer, devel...   \n",
      "6  [radiation, source, detector, quasistatic, det...   \n",
      "7  [carrier, aspect, compute, waveform, srgb, ue,...   \n",
      "8  [shaft, actuate, lock, fit, rotate, corner, st...   \n",
      "9  [light, optical, object, lidar, head, pulse, s...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [system method invention relate method system ...  \n",
      "1  [method system dynamic wireless communication ...  \n",
      "2  [present invention relate transportation manag...  \n",
      "3  [autonomous cargo container retrieval delivery...  \n",
      "4  [apparatus vessel traffic management mount ves...  \n",
      "5  [present disclosure provide signal processing ...  \n",
      "6  [method apparatus describe space charge dosime...  \n",
      "7  [prefix segment identifier sid configure use e...  \n",
      "8  [ratchet drive winch secure cargo transport ve...  \n",
      "9  [lidar system use vehicle include least proces...  \n"
     ]
    }
   ],
   "source": [
    "# 토픽 정보 출력\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cdddf5bc-922d-47e7-8673-e0489b31c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic -1: system data container device include method information item use provide\n",
      "Topic 0: network device data system signal include information method wireless communication\n",
      "Topic 1: item vehicle method system include delivery data order storage provide\n",
      "Topic 2: container cargo include system lock sensor control device position door\n",
      "Topic 3: vessel marine ship sail system position image control include least\n",
      "Topic 4: image container include form layer develop toner unit print map\n",
      "Topic 5: radiation source detector quasistatic detect field neutron container ionize radioactive\n",
      "Topic 6: carrier aspect compute waveform srgb ue transmission slice prefix synchronization\n",
      "Topic 7: shaft actuate lock fit rotate corner strap clamp pawl unit\n",
      "Topic 8: light optical object lidar head pulse scatter configure portion include\n"
     ]
    }
   ],
   "source": [
    "for topic_num in sorted(topic_model.get_topics()):\n",
    "    words = [word for word, _ in topic_model.get_topic(topic_num)]\n",
    "    print(f\"Topic {topic_num}: {' '.join(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "91a86d15-bc3b-4147-a62b-6e1169103122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Document  Topic\n",
      "0     The present specification discloses systems an...      6\n",
      "1     An inspection system based upon an imaging enc...     10\n",
      "2     A worldwide logistics network includes a proce...      0\n",
      "3     Mobile collection and vetting of user supplied...      0\n",
      "4     Systems and methods can secure freight contain...      5\n",
      "...                                                 ...    ...\n",
      "1522  The present disclosure is directed to systems ...     -1\n",
      "1523  The present disclosure relates generally to me...     -1\n",
      "1524  A system for monitoring objects and individual...      1\n",
      "1525  Provided are an active radio frequency identif...      7\n",
      "1526  A method used in the acquisition of a voice si...     -1\n",
      "\n",
      "[1527 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# 문서별 할당된 토픽\n",
    "doc_topics = pd.DataFrame({\"Document\": text_data, \"Topic\": topics})\n",
    "print(doc_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822112f1-6d96-46b9-9412-0ac87e71e036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bertopic)",
   "language": "python",
   "name": "bertopic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
